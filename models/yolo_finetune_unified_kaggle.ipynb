{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **YOLO11 Unified Dataset Training (Kaggle Version)**\n",
                "\n",
                "This notebook:\n",
                "1. **Merges** Road Lane and BDD100K datasets into a unified dataset (17 classes)\n",
                "2. **Trains** YOLO11 models on the merged dataset\n",
                "\n",
                "**Unified Classes (17 total)**\n",
                "\n",
                "| ID | Class | Source |\n",
                "|----|-------|--------|\n",
                "| 0-5 | Lane types (divider, dotted, double, random, road-sign, solid) | Road Lane |\n",
                "| 6-16 | Traffic objects (bike, bus, car, drivable area, motor, person, rider, traffic light, traffic sign, train, truck) | BDD100K |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Setup & Installation**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install ultralytics -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import shutil\n",
                "import yaml\n",
                "import time\n",
                "from pathlib import Path\n",
                "from typing import Dict, Optional\n",
                "from collections import defaultdict\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from matplotlib import pyplot as plt\n",
                "import cv2\n",
                "import torch\n",
                "from ultralytics import YOLO\n",
                "\n",
                "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f'Using device: {DEVICE}')\n",
                "if DEVICE == 'cuda':\n",
                "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Dataset Paths (Kaggle)**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Kaggle input paths\n",
                "BDD100K_DIR = Path('/kaggle/input/bdd100ka')\n",
                "ROAD_LANE_DIR = Path('/kaggle/input/roadlaneds/Road Lane.v2i.yolo26')\n",
                "\n",
                "# Output paths (writable in Kaggle)\n",
                "UNIFIED_DIR = Path('/kaggle/working/unified')\n",
                "RUNS_DIR = Path('/kaggle/working/runs')\n",
                "\n",
                "# Verify input datasets exist\n",
                "print(\"Checking input datasets...\")\n",
                "print(f\"BDD100K:    {BDD100K_DIR} - {'âœ“ Found' if BDD100K_DIR.exists() else 'âœ— NOT FOUND'}\")\n",
                "print(f\"Road Lane:  {ROAD_LANE_DIR} - {'âœ“ Found' if ROAD_LANE_DIR.exists() else 'âœ— NOT FOUND'}\")\n",
                "\n",
                "# List contents to verify structure\n",
                "if BDD100K_DIR.exists():\n",
                "    print(f\"\\nBDD100K contents: {list(BDD100K_DIR.iterdir())[:5]}\")\n",
                "if ROAD_LANE_DIR.exists():\n",
                "    print(f\"Road Lane contents: {list(ROAD_LANE_DIR.iterdir())[:5]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Step 1: Merge Datasets**\n",
                "\n",
                "Merge Road Lane (6 lane type classes) and BDD100K (11 traffic classes) into a unified dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# BDD100K class ID remapping\n",
                "# Original: ['bike', 'bus', 'car', 'drivable area', 'lane', 'motor', 'person', 'rider', 'traffic light', 'traffic sign', 'train', 'truck']\n",
                "# IDs:        0       1      2        3            4        5        6         7            8              9            10       11\n",
                "\n",
                "BDD100K_CLASS_REMAP: Dict[int, Optional[int]] = {\n",
                "    0: 6,    # bike -> 6\n",
                "    1: 7,    # bus -> 7\n",
                "    2: 8,    # car -> 8\n",
                "    3: 9,    # drivable area -> 9\n",
                "    4: None, # lane -> SKIP (replaced by Road Lane's specific lane types)\n",
                "    5: 10,   # motor -> 10\n",
                "    6: 11,   # person -> 11\n",
                "    7: 12,   # rider -> 12\n",
                "    8: 13,   # traffic light -> 13\n",
                "    9: 14,   # traffic sign -> 14\n",
                "    10: 15,  # train -> 15\n",
                "    11: 16,  # truck -> 16\n",
                "}\n",
                "\n",
                "UNIFIED_CLASS_NAMES = [\n",
                "    # Road Lane classes (0-5)\n",
                "    'divider-line', 'dotted-line', 'double-line',\n",
                "    'random-line', 'road-sign-line', 'solid-line',\n",
                "    # BDD100K classes (6-16)\n",
                "    'bike', 'bus', 'car', 'drivable area', 'motor',\n",
                "    'person', 'rider', 'traffic light', 'traffic sign', 'train', 'truck'\n",
                "]\n",
                "\n",
                "LANE_CLASSES = list(range(0, 6))\n",
                "TRAFFIC_CLASSES = list(range(6, 17))\n",
                "\n",
                "print(f\"Total unified classes: {len(UNIFIED_CLASS_NAMES)}\")\n",
                "print(f\"Lane types: {UNIFIED_CLASS_NAMES[:6]}\")\n",
                "print(f\"Traffic objects: {UNIFIED_CLASS_NAMES[6:]}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def remap_bdd100k_label(label_path: Path, output_path: Path) -> bool:\n",
                "    \"\"\"Remap BDD100K label file to unified class IDs.\"\"\"\n",
                "    lines_out = []\n",
                "    \n",
                "    with open(label_path, 'r') as f:\n",
                "        for line in f:\n",
                "            parts = line.strip().split()\n",
                "            if len(parts) < 5:\n",
                "                continue\n",
                "            \n",
                "            class_id = int(parts[0])\n",
                "            new_class_id = BDD100K_CLASS_REMAP.get(class_id)\n",
                "            \n",
                "            if new_class_id is None:\n",
                "                continue  # Skip 'lane' class\n",
                "            \n",
                "            parts[0] = str(new_class_id)\n",
                "            lines_out.append(' '.join(parts))\n",
                "    \n",
                "    if lines_out:\n",
                "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
                "        with open(output_path, 'w') as f:\n",
                "            f.write('\\n'.join(lines_out) + '\\n')\n",
                "        return True\n",
                "    return False\n",
                "\n",
                "\n",
                "def copy_road_lane_data(source_dir: Path, dest_dir: Path, split: str) -> Dict[str, int]:\n",
                "    \"\"\"Copy Road Lane data (no remapping needed).\"\"\"\n",
                "    stats = {'images': 0, 'labels': 0, 'skipped': 0}\n",
                "    \n",
                "    src_images = source_dir / split / 'images'\n",
                "    src_labels = source_dir / split / 'labels'\n",
                "    dst_images = dest_dir / split / 'images'\n",
                "    dst_labels = dest_dir / split / 'labels'\n",
                "    \n",
                "    if not src_images.exists():\n",
                "        print(f\"  Warning: {src_images} not found\")\n",
                "        return stats\n",
                "    \n",
                "    dst_images.mkdir(parents=True, exist_ok=True)\n",
                "    dst_labels.mkdir(parents=True, exist_ok=True)\n",
                "    \n",
                "    for img_path in src_images.glob('*'):\n",
                "        if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
                "            new_name = f\"roadlane_{img_path.name}\"\n",
                "            shutil.copy2(img_path, dst_images / new_name)\n",
                "            stats['images'] += 1\n",
                "            \n",
                "            label_name = img_path.stem + '.txt'\n",
                "            label_path = src_labels / label_name\n",
                "            if label_path.exists():\n",
                "                new_label_name = f\"roadlane_{label_name}\"\n",
                "                shutil.copy2(label_path, dst_labels / new_label_name)\n",
                "                stats['labels'] += 1\n",
                "            else:\n",
                "                stats['skipped'] += 1\n",
                "    \n",
                "    return stats\n",
                "\n",
                "\n",
                "def copy_bdd100k_data(source_dir: Path, dest_dir: Path, split: str) -> Dict[str, int]:\n",
                "    \"\"\"Copy BDD100K data with class remapping.\"\"\"\n",
                "    stats = {'images': 0, 'labels': 0, 'skipped': 0, 'lane_only': 0}\n",
                "    \n",
                "    src_images = source_dir / split / 'images'\n",
                "    src_labels = source_dir / split / 'labels'\n",
                "    dst_images = dest_dir / split / 'images'\n",
                "    dst_labels = dest_dir / split / 'labels'\n",
                "    \n",
                "    if not src_images.exists():\n",
                "        print(f\"  Warning: {src_images} not found\")\n",
                "        return stats\n",
                "    \n",
                "    dst_images.mkdir(parents=True, exist_ok=True)\n",
                "    dst_labels.mkdir(parents=True, exist_ok=True)\n",
                "    \n",
                "    for img_path in src_images.glob('*'):\n",
                "        if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
                "            label_name = img_path.stem + '.txt'\n",
                "            label_path = src_labels / label_name\n",
                "            \n",
                "            if not label_path.exists():\n",
                "                stats['skipped'] += 1\n",
                "                continue\n",
                "            \n",
                "            new_name = f\"bdd100k_{img_path.name}\"\n",
                "            new_label_name = f\"bdd100k_{label_name}\"\n",
                "            \n",
                "            if remap_bdd100k_label(label_path, dst_labels / new_label_name):\n",
                "                shutil.copy2(img_path, dst_images / new_name)\n",
                "                stats['images'] += 1\n",
                "                stats['labels'] += 1\n",
                "            else:\n",
                "                stats['lane_only'] += 1\n",
                "    \n",
                "    return stats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Merge datasets\n",
                "print(\"=\"*60)\n",
                "print(\"MERGING DATASETS\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "start_time = time.time()\n",
                "\n",
                "for split in ['train', 'valid', 'test']:\n",
                "    print(f\"\\nProcessing {split} split...\")\n",
                "    \n",
                "    # Road Lane\n",
                "    print(\"  Copying Road Lane data...\")\n",
                "    rl_stats = copy_road_lane_data(ROAD_LANE_DIR, UNIFIED_DIR, split)\n",
                "    print(f\"    Images: {rl_stats['images']}, Labels: {rl_stats['labels']}, Skipped: {rl_stats['skipped']}\")\n",
                "    \n",
                "    # BDD100K\n",
                "    print(\"  Copying BDD100K data (with class remapping)...\")\n",
                "    bdd_stats = copy_bdd100k_data(BDD100K_DIR, UNIFIED_DIR, split)\n",
                "    print(f\"    Images: {bdd_stats['images']}, Labels: {bdd_stats['labels']}, \"\n",
                "          f\"Skipped: {bdd_stats['skipped']}, Lane-only: {bdd_stats['lane_only']}\")\n",
                "\n",
                "merge_time = time.time() - start_time\n",
                "print(f\"\\nâœ“ Dataset merge completed in {merge_time:.1f} seconds\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create unified data.yaml\n",
                "data_yaml_content = {\n",
                "    'train': str(UNIFIED_DIR / 'train' / 'images'),\n",
                "    'val': str(UNIFIED_DIR / 'valid' / 'images'),\n",
                "    'test': str(UNIFIED_DIR / 'test' / 'images'),\n",
                "    'nc': 17,\n",
                "    'names': UNIFIED_CLASS_NAMES\n",
                "}\n",
                "\n",
                "UNIFIED_YAML = UNIFIED_DIR / 'data_unified.yaml'\n",
                "with open(UNIFIED_YAML, 'w') as f:\n",
                "    yaml.dump(data_yaml_content, f, default_flow_style=False)\n",
                "\n",
                "print(f\"Created: {UNIFIED_YAML}\")\n",
                "print(f\"\\nContents:\")\n",
                "with open(UNIFIED_YAML, 'r') as f:\n",
                "    print(f.read())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validate merged dataset\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"DATASET VALIDATION\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "class_counts = defaultdict(int)\n",
                "total_images = 0\n",
                "total_labels = 0\n",
                "\n",
                "for split in ['train', 'valid', 'test']:\n",
                "    images_dir = UNIFIED_DIR / split / 'images'\n",
                "    labels_dir = UNIFIED_DIR / split / 'labels'\n",
                "    \n",
                "    if not images_dir.exists():\n",
                "        continue\n",
                "    \n",
                "    n_images = len(list(images_dir.glob('*')))\n",
                "    n_labels = len(list(labels_dir.glob('*.txt')))\n",
                "    \n",
                "    print(f\"\\n{split}:\")\n",
                "    print(f\"  Images: {n_images}\")\n",
                "    print(f\"  Labels: {n_labels}\")\n",
                "    \n",
                "    total_images += n_images\n",
                "    total_labels += n_labels\n",
                "    \n",
                "    # Count classes\n",
                "    for label_path in labels_dir.glob('*.txt'):\n",
                "        with open(label_path, 'r') as f:\n",
                "            for line in f:\n",
                "                parts = line.strip().split()\n",
                "                if parts:\n",
                "                    class_id = int(parts[0])\n",
                "                    class_counts[class_id] += 1\n",
                "\n",
                "print(f\"\\nTotal: {total_images} images, {total_labels} labels\")\n",
                "\n",
                "print(\"\\nClass Distribution:\")\n",
                "print(\"-\" * 40)\n",
                "for class_id in sorted(class_counts.keys()):\n",
                "    name = UNIFIED_CLASS_NAMES[class_id] if class_id < len(UNIFIED_CLASS_NAMES) else f\"unknown_{class_id}\"\n",
                "    count = class_counts[class_id]\n",
                "    category = \"Lane\" if class_id < 6 else \"Traffic\"\n",
                "    print(f\"  {class_id:2d} [{category:7s}] {name:15s}: {count:,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Step 2: Training Configuration**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Enhanced training configuration\n",
                "TRAINING_CONFIG = {\n",
                "    # Core settings\n",
                "    'epochs': 100,           # More epochs for better convergence\n",
                "    'imgsz': 640,            # Image size\n",
                "    'batch': 16,             # Batch size (reduce if GPU OOM)\n",
                "    'patience': 20,          # Early stopping patience\n",
                "    'device': DEVICE,        # Training device\n",
                "    'workers': 4,            # Data loader workers\n",
                "    \n",
                "    # Learning rate settings\n",
                "    'lr0': 0.01,             # Initial learning rate\n",
                "    'lrf': 0.01,             # Final learning rate (lr0 * lrf)\n",
                "    'warmup_epochs': 3,      # Warmup epochs\n",
                "    'warmup_momentum': 0.8,  # Warmup initial momentum\n",
                "    'cos_lr': True,          # Cosine learning rate scheduler\n",
                "    \n",
                "    # Optimizer\n",
                "    'optimizer': 'AdamW',    # AdamW optimizer\n",
                "    'momentum': 0.937,       # SGD momentum/Adam beta1\n",
                "    'weight_decay': 0.0005,  # Weight decay\n",
                "    \n",
                "    # Data augmentation\n",
                "    'hsv_h': 0.015,\n",
                "    'hsv_s': 0.7,\n",
                "    'hsv_v': 0.4,\n",
                "    'degrees': 0.0,          # Disabled for driving scenes\n",
                "    'translate': 0.1,\n",
                "    'scale': 0.5,\n",
                "    'fliplr': 0.5,\n",
                "    'mosaic': 1.0,\n",
                "    'mixup': 0.1,\n",
                "    \n",
                "    # Output\n",
                "    'save': True,\n",
                "    'save_period': 10,\n",
                "    'plots': True,\n",
                "    'verbose': True,\n",
                "}\n",
                "\n",
                "print(\"Training Configuration\")\n",
                "print(\"=\"*50)\n",
                "for key in ['epochs', 'imgsz', 'batch', 'lr0', 'cos_lr', 'optimizer']:\n",
                "    print(f\"  {key}: {TRAINING_CONFIG[key]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Step 3: Train YOLO11n on Unified Dataset**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load pretrained YOLO11n\n",
                "print('Loading pretrained YOLO11n...')\n",
                "model_n = YOLO('yolo11n.pt')\n",
                "model_n.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train YOLO11n\n",
                "print('='*60)\n",
                "print('Training YOLO11n on Unified Dataset (17 classes)')\n",
                "print('='*60)\n",
                "\n",
                "start_time = time.time()\n",
                "\n",
                "results_n = model_n.train(\n",
                "    data=str(UNIFIED_YAML),\n",
                "    project=str(RUNS_DIR / 'finetune'),\n",
                "    name='yolo11n_unified',\n",
                "    exist_ok=True,\n",
                "    **TRAINING_CONFIG\n",
                ")\n",
                "\n",
                "training_time_n = time.time() - start_time\n",
                "print(f'\\nâœ“ YOLO11n training completed in {training_time_n/3600:.2f} hours')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Step 4: Train YOLO11l on Unified Dataset**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load pretrained YOLO11l\n",
                "print('Loading pretrained YOLO11l...')\n",
                "model_l = YOLO('yolo11l.pt')\n",
                "model_l.info()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train YOLO11l (reduced batch size)\n",
                "print('='*60)\n",
                "print('Training YOLO11l on Unified Dataset (17 classes)')\n",
                "print('='*60)\n",
                "\n",
                "config_l = TRAINING_CONFIG.copy()\n",
                "config_l['batch'] = 8  # Reduced for larger model\n",
                "\n",
                "start_time = time.time()\n",
                "\n",
                "results_l = model_l.train(\n",
                "    data=str(UNIFIED_YAML),\n",
                "    project=str(RUNS_DIR / 'finetune'),\n",
                "    name='yolo11l_unified',\n",
                "    exist_ok=True,\n",
                "    **config_l\n",
                ")\n",
                "\n",
                "training_time_l = time.time() - start_time\n",
                "print(f'\\nâœ“ YOLO11l training completed in {training_time_l/3600:.2f} hours')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Step 5: Validate & Compare Models**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_model(model_path, dataset_yaml, model_name):\n",
                "    \"\"\"Evaluate model and return metrics.\"\"\"\n",
                "    model = YOLO(str(model_path))\n",
                "    \n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Evaluating {model_name}\")\n",
                "    print(f\"{'='*60}\")\n",
                "    \n",
                "    metrics = model.val(data=str(dataset_yaml), split='test', verbose=False)\n",
                "    \n",
                "    # Overall\n",
                "    print(f\"\\nmAP50:     {metrics.box.map50:.4f}\")\n",
                "    print(f\"mAP50-95:  {metrics.box.map:.4f}\")\n",
                "    print(f\"Precision: {metrics.box.mp:.4f}\")\n",
                "    print(f\"Recall:    {metrics.box.mr:.4f}\")\n",
                "    \n",
                "    # Per-category\n",
                "    ap50 = metrics.box.ap50\n",
                "    lane_map = np.mean([ap50[i] for i in LANE_CLASSES if i < len(ap50)])\n",
                "    traffic_map = np.mean([ap50[i] for i in TRAFFIC_CLASSES if i < len(ap50)])\n",
                "    \n",
                "    print(f\"\\nLane Types mAP50:     {lane_map:.4f}\")\n",
                "    print(f\"Traffic Objects mAP50: {traffic_map:.4f}\")\n",
                "    \n",
                "    return {\n",
                "        'model': model_name,\n",
                "        'map50': metrics.box.map50,\n",
                "        'map': metrics.box.map,\n",
                "        'precision': metrics.box.mp,\n",
                "        'recall': metrics.box.mr,\n",
                "        'lane_map50': lane_map,\n",
                "        'traffic_map50': traffic_map\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate both models\n",
                "results = []\n",
                "\n",
                "n_path = RUNS_DIR / 'finetune' / 'yolo11n_unified' / 'weights' / 'best.pt'\n",
                "l_path = RUNS_DIR / 'finetune' / 'yolo11l_unified' / 'weights' / 'best.pt'\n",
                "\n",
                "if n_path.exists():\n",
                "    results.append(evaluate_model(n_path, UNIFIED_YAML, 'YOLO11n Unified'))\n",
                "\n",
                "if l_path.exists():\n",
                "    results.append(evaluate_model(l_path, UNIFIED_YAML, 'YOLO11l Unified'))\n",
                "\n",
                "# Summary table\n",
                "if results:\n",
                "    df = pd.DataFrame(results)\n",
                "    print(\"\\n\" + \"=\"*80)\n",
                "    print(\"MODEL COMPARISON SUMMARY\")\n",
                "    print(\"=\"*80)\n",
                "    display(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Step 6: Visual Inference Test**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test inference\n",
                "test_dir = UNIFIED_DIR / 'test' / 'images'\n",
                "best_model = YOLO(str(n_path)) if n_path.exists() else None\n",
                "\n",
                "if best_model and test_dir.exists():\n",
                "    sample_images = list(test_dir.glob('*.jpg'))[:6]\n",
                "    \n",
                "    if sample_images:\n",
                "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "        axes = axes.flatten()\n",
                "        \n",
                "        for idx, img_path in enumerate(sample_images):\n",
                "            results = best_model.predict(str(img_path), verbose=False, conf=0.25)\n",
                "            annotated = results[0].plot()\n",
                "            annotated = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
                "            \n",
                "            axes[idx].imshow(annotated)\n",
                "            source = \"Lane\" if 'roadlane' in img_path.name else \"Traffic\"\n",
                "            axes[idx].set_title(f\"[{source}] {img_path.name[:25]}...\", fontsize=9)\n",
                "            axes[idx].axis('off')\n",
                "            \n",
                "            # Count detections\n",
                "            if results[0].boxes is not None:\n",
                "                classes = results[0].boxes.cls.cpu().numpy().astype(int)\n",
                "                lane_cnt = sum(1 for c in classes if c < 6)\n",
                "                traffic_cnt = sum(1 for c in classes if c >= 6)\n",
                "                print(f\"{img_path.name}: Lanes={lane_cnt}, Traffic={traffic_cnt}\")\n",
                "        \n",
                "        plt.tight_layout()\n",
                "        plt.savefig(str(RUNS_DIR / 'inference_samples.png'), dpi=150)\n",
                "        plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Step 7: Save Models**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Copy best models to output\n",
                "output_dir = Path('/kaggle/working/models')\n",
                "output_dir.mkdir(exist_ok=True)\n",
                "\n",
                "for src, name in [(n_path, 'yolo11n_unified_best.pt'), (l_path, 'yolo11l_unified_best.pt')]:\n",
                "    if src.exists():\n",
                "        shutil.copy2(src, output_dir / name)\n",
                "        print(f\"âœ“ Saved: {output_dir / name}\")\n",
                "\n",
                "print(f\"\\nModels saved to: {output_dir}\")\n",
                "print(\"Download these from the Output tab.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Training Complete! ðŸŽ‰**\n",
                "\n",
                "The unified models detect:\n",
                "- âœ… **6 lane types**: divider, dotted, double, random, road-sign, solid\n",
                "- âœ… **11 traffic objects**: bike, bus, car, drivable area, motor, person, rider, traffic light, traffic sign, train, truck"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "gpu",
            "dataSources": [],
            "dockerImageVersionId": 30919,
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
